{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## select variables to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected variable names by category\n",
    "file_path = 'subsets/'\n",
    "\n",
    "health_pca_var_names = [var for var in pd.read_fwf(file_path +'health-PCA.txt',header=None)[0]]\n",
    "credit_pca_var_names = [var for var in pd.read_fwf(file_path + 'credit-PCA.txt',header=None)[0]]\n",
    "med_pay_pca_var_names = [var for var in pd.read_fwf(file_path + 'medical-payment-PCA.txt',header=None)[0]]\n",
    "var_names = [var for var in pd.read_fwf(file_path + 'other-variables.txt',header=None)[0]]\n",
    "\n",
    "# all selected\n",
    "all_vars = health_pca_var_names + credit_pca_var_names + med_pay_pca_var_names + var_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read train and holdout files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataframes by categories\n",
    "df_all =  pd.read_csv('data/2020_Competition_Training.csv', usecols=all_vars,low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, 297)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "df_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_holdout = pd.read_csv('data/2020_Competition_Holdout.csv', usecols=all_vars,low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17681, 297)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_holdout.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_none_missing_values(col):\n",
    "    \n",
    "    '''\n",
    "    Encoding a column by dividing the column into missing values and no missing values, \n",
    "    and only encode no missing values. Then append the missing values to the encoded values. \n",
    "    Return the encoded column.\n",
    "    '''\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "    le = preprocessing.LabelEncoder()\n",
    "\n",
    "    missing_vals = col[col.isnull()]\n",
    "    no_missing = col[~col.isnull()]\n",
    "    \n",
    "    no_missing_t = le.fit_transform(no_missing)\n",
    "    no_missing = pd.Series(no_missing_t, index = no_missing.index)\n",
    "    col_new = pd.concat([no_missing, missing_vals]).sort_index()\n",
    "    return col_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prepration(df, k):\n",
    "    \n",
    "    \"\"\"\n",
    "    Encode all \"object\" columns and impute missing values. Takes in a dataframe and k value for KNN imputation.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df_names = df.columns\n",
    "    df[\"lang_spoken_cd\"].replace(\"E\", \"ENG\", inplace = True) # Encode \"E\" as \"ENG\"\n",
    "    \n",
    "    # encode non-missing values for categorical variables\n",
    "    \n",
    "    encode_df = df.select_dtypes(include = \"object\")\n",
    "    encode_df = encode_df.copy()\n",
    "    for (columnName, columnData) in encode_df.iteritems(): \n",
    "        new_col = encoding_none_missing_values(columnData)\n",
    "        encode_df.loc[:,columnName] = new_col\n",
    "    \n",
    "    df.loc[:,df_all.columns.isin(encode_df.columns)] = encode_df\n",
    "    \n",
    "    # impute missing values\n",
    "    \n",
    "    n = df.shape[0]\n",
    "    prev = 0\n",
    "    num_it = math.ceil(n/10000) # total number of iteration (dataset > 10000 rows)\n",
    "    \n",
    "    # rangess for slicing for each imputation (due to limit computing power, maximum 10000 rows at once)\n",
    "    list_range = []                  \n",
    "    for i in range(num_it):\n",
    "        if i < num_it-1:\n",
    "            now = prev + 10000\n",
    "            list_range.append((prev, now))\n",
    "            prev = now\n",
    "        else:\n",
    "            now = n\n",
    "            list_range.append((prev, now))          \n",
    "            \n",
    "    # KNN imputation\n",
    "    imputer = KNNImputer(n_neighbors=k)\n",
    "\n",
    "    df_list = []\n",
    "    for t in list_range:\n",
    "        df_i = pd.DataFrame(imputer.fit_transform(df_all[t[0]:t[1]]))\n",
    "        df_list.append(df_i)\n",
    "    imputed = pd.concat(df_list)\n",
    "    imputed.columns = df_names\n",
    "    # return the imputed dataframe\n",
    "    return imputed\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = data_prepration(df_all, 2)\n",
    "holdout = data_prepration(df_all_holdout, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## principal component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_health = PCA(n_components = 80)\n",
    "df_pca_health_train = pca_health.fit_transform(train[health_pca_var_names])\n",
    "df_pca_health_holdout = pca_health.transform(holdout[health_pca_var_names])\n",
    "\n",
    "\n",
    "pca_credit = PCA(n_components = 5)\n",
    "df_pca_credit_train = pca_credit.fit_transform(train[credit_pca_var_names])\n",
    "df_pca_credit_holdout = pca_credit.transform(holdout[credit_pca_var_names])\n",
    "\n",
    "\n",
    "pca_med_pay = PCA(n_components = 4)\n",
    "df_pca_med_pay_train = pca_med_pay.fit_transform(train[med_pay_pca_var_names])\n",
    "df_pca_med_pay_holdout = pca_med_pay.transform(holdout[med_pay_pca_var_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_train = pd.concat(df_pca_health_train, df_pca_credit_train, df_pca_med_pay_train, train[var_names])\n",
    "pca_holdout = pd.concat(df_pca_health_holdout, df_pca_credit_holdout, df_pca_med_pay_holdout, holdout[var_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "health_pca_name = []\n",
    "for i in range(80):\n",
    "    name = \"health_pc\" + str(i+1)\n",
    "    health_pca_name.append(name)\n",
    "    \n",
    "credit_pca_name = []\n",
    "for i in range(5):\n",
    "    name = \"credit_pc\" + str(i+1)\n",
    "    credit_pca_name.append(name)  \n",
    "\n",
    "medpat_pca_name = []    \n",
    "for i in range(4):\n",
    "    name = \"medpay_pc\" + str(i+1)\n",
    "    medpat_pca_name.append(name) \n",
    "\n",
    "names_pca = health_pca_name + credit_pca_name + medpat_pca_name + var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_train.columns = names_pca\n",
    "pca_holdout.columns = names_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_train.to_csv(\"pca_train.csv\")\n",
    "# pca_holdout.to_csv(\"pca_holdout.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
